{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0251f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import (\n",
    "    split, lower, explode, regexp_replace,\n",
    "    lit, array_contains, regexp_extract, col, when\n",
    ")\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c610f28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/01/14 21:58:16 WARN Utils: Your hostname, DMPC, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "26/01/14 21:58:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/14 21:58:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos encontrados: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|  doc|               texto|\n",
      "+-----+--------------------+\n",
      "|  100|﻿The Project Gute...|\n",
      "| 1023|﻿The Project Gute...|\n",
      "|10554|﻿The Project Gute...|\n",
      "| 1080|﻿The Project Gute...|\n",
      "|   11|﻿The Project Gute...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Books_TFIDF').getOrCreate()\n",
    "\n",
    "carpeta = './libros/*.txt'  \n",
    "rdd = spark.sparkContext.wholeTextFiles(carpeta)\n",
    "\n",
    "print(\"Archivos encontrados:\", rdd.count())\n",
    "\n",
    "df = rdd.toDF(['ruta', 'texto'])\n",
    "df = df.withColumn('doc', regexp_extract('ruta', r'([^/]+$)', 1))\n",
    "df = df.withColumn('doc', regexp_replace('doc', '\\\\.txt$', ''))\n",
    "df = df.select('doc', 'texto')\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35dc8d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|  doc|               texto|\n",
      "+-----+--------------------+\n",
      "|  100|The Project Guten...|\n",
      "| 1023|The Project Guten...|\n",
      "|10554|The Project Guten...|\n",
      "| 1080|The Project Guten...|\n",
      "|   11|The Project Guten...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "def limpiar_texto(df, columna):\n",
    "    return df.withColumn(\n",
    "        columna,\n",
    "        regexp_replace(columna, '[^a-zA-Z0-9\\\\s]', '')\n",
    "    )\n",
    "\n",
    "df_clean = limpiar_texto(df, 'texto')\n",
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc103262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------------------------------+\n",
      "|  doc|                                          palabras|\n",
      "+-----+--------------------------------------------------+\n",
      "|  100|[the, project, gutenberg, ebook, of, the, compl...|\n",
      "| 1023|[the, project, gutenberg, ebook, of, bleak, hou...|\n",
      "|10554|[the, project, gutenberg, ebook, of, right, ho,...|\n",
      "+-----+--------------------------------------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "df_tokens = df_clean.withColumn(\n",
    "    'palabras',\n",
    "    split(lower(col('texto')), '\\\\s+')\n",
    ")\n",
    "\n",
    "df_tokens.select('doc', 'palabras').show(3, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e464d013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------------------------------+--------------------------------------------------+\n",
      "|  doc|                                             texto|                                          palabras|\n",
      "+-----+--------------------------------------------------+--------------------------------------------------+\n",
      "|  100|The Project Gutenberg eBook of The Complete Wor...|[project, gutenberg, ebook, complete, works, wi...|\n",
      "| 1023|The Project Gutenberg eBook of Bleak House\\r\\n ...|[project, gutenberg, ebook, bleak, house, ebook...|\n",
      "|10554|The Project Gutenberg eBook of Right Ho Jeeves\\...|[project, gutenberg, ebook, right, ho, jeeves, ...|\n",
      "+-----+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "df_tokens_filtrado = df_tokens.withColumn(\n",
    "    'palabras',\n",
    "    F.filter('palabras', lambda x: ~array_contains(lit(stop_words), x))\n",
    ")\n",
    "\n",
    "df_tokens_filtrado.show(3, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd3b1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "|doc|     palabra|\n",
      "+---+------------+\n",
      "|100|     project|\n",
      "|100|   gutenberg|\n",
      "|100|       ebook|\n",
      "|100|    complete|\n",
      "|100|       works|\n",
      "|100|     william|\n",
      "|100| shakespeare|\n",
      "|100|       ebook|\n",
      "|100|         use|\n",
      "|100|      anyone|\n",
      "|100|    anywhere|\n",
      "|100|      united|\n",
      "|100|      states|\n",
      "|100|       parts|\n",
      "|100|       world|\n",
      "|100|        cost|\n",
      "|100|      almost|\n",
      "|100|restrictions|\n",
      "|100|  whatsoever|\n",
      "|100|         may|\n",
      "+---+------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_explode = (\n",
    "    df_tokens_filtrado\n",
    "    .withColumn('palabra', explode('palabras'))\n",
    "    .select('doc', 'palabra')\n",
    "    .filter(col('palabra') != '')\n",
    ")\n",
    "\n",
    "df_explode.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a7ed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=============================>                             (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "|doc|   palabra|                  tf|\n",
      "+---+----------+--------------------+\n",
      "|100|profitless|5.793619679767329E-6|\n",
      "|100|  destroys|3.862413119844885E-6|\n",
      "|100|     lofty|3.476171807860397E-5|\n",
      "|100|  thoughts|5.272193908588269E-4|\n",
      "|100|  bettring|1.931206559922442...|\n",
      "|100|       sea|4.692831940611535...|\n",
      "|100| antiquity|1.351844591945709...|\n",
      "|100|    fleece|1.931206559922442...|\n",
      "|100|    yellow|5.793619679767328E-5|\n",
      "|100|   contain|3.283051151868153E-5|\n",
      "|100|   compile|3.862413119844885E-6|\n",
      "|100|  abundant| 7.72482623968977E-6|\n",
      "|100|    spoils|2.317447871906931...|\n",
      "|100|  answered|6.952343615720794E-5|\n",
      "|100|   invited|1.931206559922442...|\n",
      "|100|     angel|1.120099804755016...|\n",
      "|100|    refuse|6.372981647744062E-5|\n",
      "|100|warrantise|1.931206559922442...|\n",
      "|100| adoptious|1.931206559922442...|\n",
      "|100|   modesty|1.042851542358119E-4|\n",
      "+---+----------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_word_count = df_explode.groupBy('doc', 'palabra').count()\n",
    "\n",
    "df_doc_size = (\n",
    "    df_explode.groupBy('doc').count()\n",
    "    .withColumnRenamed('count', 'total_palabras')\n",
    ")\n",
    "\n",
    "df_TF = (\n",
    "    df_word_count\n",
    "    .join(df_doc_size, on='doc')\n",
    "    .withColumn('tf', col('count') / col('total_palabras'))\n",
    "    .select('doc', 'palabra', 'tf')\n",
    ")\n",
    "\n",
    "df_TF.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0054355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:====================================>                     (5 + 3) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+\n",
      "|       palabra| df|\n",
      "+--------------+---+\n",
      "|           vor|  9|\n",
      "|        harder| 72|\n",
      "|        20253m|  1|\n",
      "|           fog| 64|\n",
      "|          hope|153|\n",
      "|        online|152|\n",
      "|         cures| 31|\n",
      "|        vortex| 17|\n",
      "|         trail| 44|\n",
      "|        chiuse|  1|\n",
      "| modernasalute|  1|\n",
      "|     connected|107|\n",
      "|    cineration|  1|\n",
      "|achtungswrdige|  1|\n",
      "|       courted| 26|\n",
      "|      glafiras|  1|\n",
      "|         still|147|\n",
      "|       implore| 43|\n",
      "|    occidental|  9|\n",
      "|  bottleeither|  1|\n",
      "+--------------+---+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_unique = df_explode.select('doc', 'palabra').distinct()\n",
    "\n",
    "df_DF = (\n",
    "    df_unique.groupBy('palabra').count()\n",
    "    .withColumnRenamed('count', 'df')\n",
    ")\n",
    "\n",
    "df_DF.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e57a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 2) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de documentos: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "N = df.select('doc').distinct().count()\n",
    "print('Total de documentos:', N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57361138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "|doc|   palabra|                  tf|\n",
      "+---+----------+--------------------+\n",
      "|100|profitless|5.793619679767329E-6|\n",
      "|100|  destroys|3.862413119844885E-6|\n",
      "|100|     lofty|3.476171807860397E-5|\n",
      "|100|  thoughts|5.272193908588269E-4|\n",
      "|100|  bettring|1.931206559922442...|\n",
      "|100|       sea|4.692831940611535...|\n",
      "|100| antiquity|1.351844591945709...|\n",
      "|100|    fleece|1.931206559922442...|\n",
      "|100|    yellow|5.793619679767328E-5|\n",
      "|100|   contain|3.283051151868153E-5|\n",
      "|100|   compile|3.862413119844885E-6|\n",
      "|100|  abundant| 7.72482623968977E-6|\n",
      "|100|    spoils|2.317447871906931...|\n",
      "|100|  answered|6.952343615720794E-5|\n",
      "|100|   invited|1.931206559922442...|\n",
      "|100|     angel|1.120099804755016...|\n",
      "|100|    refuse|6.372981647744062E-5|\n",
      "|100|warrantise|1.931206559922442...|\n",
      "|100| adoptious|1.931206559922442...|\n",
      "|100|   modesty|1.042851542358119E-4|\n",
      "+---+----------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Conteo de palabras por documento\n",
    "df_word_count = df_explode.groupBy('doc', 'palabra').count()\n",
    "\n",
    "# Total de palabras por documento\n",
    "df_doc_size = (\n",
    "    df_explode\n",
    "    .groupBy('doc')\n",
    "    .count()\n",
    "    .withColumnRenamed('count', 'total_palabras')\n",
    ")\n",
    "\n",
    "# TF = frecuencia / total de palabras del documento\n",
    "df_TF = (\n",
    "    df_word_count\n",
    "    .join(df_doc_size, on='doc')\n",
    "    .withColumn('tf', col('count') / col('total_palabras'))\n",
    "    .select('doc', 'palabra', 'tf')\n",
    ")\n",
    "\n",
    "df_TF.show(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe070cdc-32ad-4c76-a8d9-ccd9039d53b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m col, lit\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Número total de documentos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m N = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdoc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.distinct().count()\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTotal documentos:\u001b[39m\u001b[33m\"\u001b[39m, N)\n\u001b[32m      8\u001b[39m df_TFIDF = (\n\u001b[32m      9\u001b[39m     df_TF\n\u001b[32m     10\u001b[39m     .join(df_DF, on=\u001b[33m'\u001b[39m\u001b[33mpalabra\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     .select(\u001b[33m'\u001b[39m\u001b[33mdoc\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpalabra\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtfidf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:991\u001b[39m, in \u001b[36mDataFrame.select\u001b[39m\u001b[34m(self, *cols)\u001b[39m\n\u001b[32m    990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cols: \u001b[33m\"\u001b[39m\u001b[33mColumnOrName\u001b[39m\u001b[33m\"\u001b[39m) -> ParentDataFrame:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     jdf = \u001b[38;5;28mself\u001b[39m._jdf.select(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    992\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:890\u001b[39m, in \u001b[36mDataFrame._jcols\u001b[39m\u001b[34m(self, *cols)\u001b[39m\n\u001b[32m    888\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cols[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    889\u001b[39m     cols = cols[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_to_java_column\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:877\u001b[39m, in \u001b[36mDataFrame._jseq\u001b[39m\u001b[34m(self, cols, converter)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_jseq\u001b[39m(\n\u001b[32m    872\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    873\u001b[39m     cols: Sequence,\n\u001b[32m    874\u001b[39m     converter: Optional[Callable[..., Union[\u001b[33m\"\u001b[39m\u001b[33mPrimitiveType\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mJavaObject\u001b[39m\u001b[33m\"\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    875\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mJavaObject\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    876\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m877\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/pyspark/sql/classic/column.py:104\u001b[39m, in \u001b[36m_to_seq\u001b[39m\u001b[34m(sc, cols, converter)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[33;03mConvert a list of Columns (or names) into a JVM Seq of Column.\u001b[39;00m\n\u001b[32m     99\u001b[39m \n\u001b[32m    100\u001b[39m \u001b[33;03mAn optional `converter` could be used to convert items in `cols`\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03minto JVM Column objects.\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m converter:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     cols = [\u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols]\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m sc._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sc._jvm.PythonUtils.toSeq(cols)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/pyspark/sql/classic/column.py:69\u001b[39m, in \u001b[36m_to_java_column\u001b[39m\u001b[34m(col)\u001b[39m\n\u001b[32m     67\u001b[39m     jcol = col._jc\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     jcol = \u001b[43m_create_column_from_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[32m     72\u001b[39m         errorClass=\u001b[33m\"\u001b[39m\u001b[33mNOT_COLUMN_OR_STR\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     73\u001b[39m         messageParameters={\u001b[33m\"\u001b[39m\u001b[33marg_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33marg_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col).\u001b[34m__name__\u001b[39m},\n\u001b[32m     74\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/pyspark/sql/classic/column.py:62\u001b[39m, in \u001b[36m_create_column_from_name\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjava_gateway\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JVMView\n\u001b[32m     61\u001b[39m sc = get_active_spark_context()\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJVMView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctions\u001b[49m.col(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/py4j/java_gateway.py:1752\u001b[39m, in \u001b[36mJVMView.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1749\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == UserHelpAutoCompletion.KEY:\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[32m-> \u001b[39m\u001b[32m1752\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gateway_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1753\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m.\u001b[49m\u001b[43mREFLECTION_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m   1754\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m.\u001b[49m\u001b[43mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m   1755\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEND_COMMAND_PART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer == proto.SUCCESS_PACKAGE:\n\u001b[32m   1757\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaPackage(name, \u001b[38;5;28mself\u001b[39m._gateway_client, jvm_id=\u001b[38;5;28mself\u001b[39m._id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/py4j/java_gateway.py:1036\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry=\u001b[38;5;28;01mTrue\u001b[39;00m, binary=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1016\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[32m   1017\u001b[39m \u001b[33;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[33;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1034\u001b[39m \u001b[33;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m     connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m         response = connection.send_command(command)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/py4j/clientserver.py:284\u001b[39m, in \u001b[36mJavaClient._get_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection.socket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/py4j/clientserver.py:291\u001b[39m, in \u001b[36mJavaClient._create_new_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    288\u001b[39m     connection = ClientServerConnection(\n\u001b[32m    289\u001b[39m         \u001b[38;5;28mself\u001b[39m.java_parameters, \u001b[38;5;28mself\u001b[39m.python_parameters,\n\u001b[32m    290\u001b[39m         \u001b[38;5;28mself\u001b[39m.gateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_thread_connection(connection)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sparkenv/lib/python3.12/site-packages/py4j/clientserver.py:438\u001b[39m, in \u001b[36mClientServerConnection.connect_to_java_server\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ssl_context:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.socket = \u001b[38;5;28mself\u001b[39m.ssl_context.wrap_socket(\n\u001b[32m    437\u001b[39m         \u001b[38;5;28mself\u001b[39m.socket, server_hostname=\u001b[38;5;28mself\u001b[39m.java_address)\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.stream = \u001b[38;5;28mself\u001b[39m.socket.makefile(\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    440\u001b[39m \u001b[38;5;28mself\u001b[39m.is_connected = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# Número total de documentos\n",
    "N = df.select('doc').distinct().count()\n",
    "print(\"Total documentos:\", N)\n",
    "\n",
    "df_TFIDF = (\n",
    "    df_TF\n",
    "    .join(df_DF, on='palabra')\n",
    "    .withColumn(\n",
    "        'tfidf',\n",
    "        col('tf') * F.log10(lit(1) + (lit(N) / col('df')))\n",
    "    )\n",
    "    .select('doc', 'palabra', 'tfidf')\n",
    ")\n",
    "\n",
    "df_TFIDF.show(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99802118-1a5c-4cdf-add8-d7be3e6100bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
